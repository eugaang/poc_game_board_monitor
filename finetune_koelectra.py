"""
KoELECTRA Fine-tuning Script
ê²Œì„ ì»¤ë®¤ë‹ˆí‹° ê°ì • ë¶„ì„ì„ ìœ„í•œ KoELECTRA ëª¨ë¸ Fine-tuning

ì‚¬ìš©ë²•:
    python finetune_koelectra.py
"""

import os
import pandas as pd
import numpy as np
import torch
from datasets import Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback
)
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# ============================================
# ì„¤ì •
# ============================================

CONFIG = {
    "model_name": "monologg/koelectra-base-v3-discriminator",
    "train_file": "data/train_koelectra_120.csv",
    "val_file": "data/val_koelectra_30.csv",
    "output_dir": "./koelectra-finetuned",
    "max_length": 512,
    "num_labels": 3,  # 0=ë¶€ì •, 1=ì¤‘ë¦½, 2=ê¸ì •
    
    # í•™ìŠµ ì„¤ì •
    "num_train_epochs": 5,  # ì „ì²´ ë°ì´í„°ë¥¼ 5ë²ˆ í•™ìŠµ
    "batch_size": 8,
    "learning_rate": 2e-5,
    "weight_decay": 0.01,
    
    # ê¸°íƒ€
    "seed": 42,
    "use_gpu": torch.cuda.is_available()
}

print("="*60)
print("ğŸ¤– KoELECTRA Fine-tuning")
print("="*60)
print(f"ğŸ“Š Train data: {CONFIG['train_file']}")
print(f"ğŸ“Š Val data: {CONFIG['val_file']}")
print(f"ğŸ”§ Model: {CONFIG['model_name']}")
print(f"ğŸ’» Device: {'GPU' if CONFIG['use_gpu'] else 'CPU'}")
print(f"ğŸ“ Epochs: {CONFIG['num_train_epochs']}")
print(f"ğŸ“¦ Batch size: {CONFIG['batch_size']}")
print("="*60)

# ============================================
# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ============================================

print("\nğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

# CSV ì½ê¸°
train_df = pd.read_csv(CONFIG["train_file"])
val_df = pd.read_csv(CONFIG["val_file"])

# í…ìŠ¤íŠ¸ ê²°í•© (title + content)
train_df["text"] = train_df["title"].fillna("") + " " + train_df["content"].fillna("")
val_df["text"] = val_df["title"].fillna("") + " " + val_df["content"].fillna("")

# ë ˆì´ë¸” í™•ì¸
print(f"âœ… Train: {len(train_df)}ê°œ")
print(f"âœ… Val: {len(val_df)}ê°œ")
print(f"\nğŸ“Š ë ˆì´ë¸” ë¶„í¬ (Train):")
print(train_df["sentiment_label"].value_counts().sort_index())
print(f"\nğŸ“Š ë ˆì´ë¸” ë¶„í¬ (Val):")
print(val_df["sentiment_label"].value_counts().sort_index())

# Dataset ë³€í™˜
train_dataset = Dataset.from_dict({
    "text": train_df["text"].tolist(),
    "label": train_df["sentiment_label"].tolist()
})

val_dataset = Dataset.from_dict({
    "text": val_df["text"].tolist(),
    "label": val_df["sentiment_label"].tolist()
})

# ============================================
# 2. í† í¬ë‚˜ì´ì € ë¡œë“œ ë° í† í°í™”
# ============================================

print("\nğŸ”¤ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...")

tokenizer = AutoTokenizer.from_pretrained(CONFIG["model_name"])

def preprocess_function(examples):
    """í…ìŠ¤íŠ¸ë¥¼ í† í°í™”"""
    return tokenizer(
        examples["text"],
        truncation=True,
        padding="max_length",
        max_length=CONFIG["max_length"]
    )

print("ğŸ”¤ í† í°í™” ì§„í–‰ ì¤‘...")
train_dataset = train_dataset.map(preprocess_function, batched=True)
val_dataset = val_dataset.map(preprocess_function, batched=True)

print("âœ… í† í°í™” ì™„ë£Œ!")

# ============================================
# 3. ëª¨ë¸ ë¡œë“œ
# ============================================

print(f"\nğŸ¤– ëª¨ë¸ ë¡œë”© ì¤‘: {CONFIG['model_name']}")

model = AutoModelForSequenceClassification.from_pretrained(
    CONFIG["model_name"],
    num_labels=CONFIG["num_labels"],
    problem_type="single_label_classification"
)

print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# ============================================
# 4. í‰ê°€ í•¨ìˆ˜ ì •ì˜
# ============================================

def compute_metrics(pred):
    """í‰ê°€ ì§€í‘œ ê³„ì‚°"""
    labels = pred.label_ids
    preds = np.argmax(pred.predictions, axis=1)
    
    # ì •í™•ë„
    acc = accuracy_score(labels, preds)
    
    # Precision, Recall, F1
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, preds, average='weighted', zero_division=0
    )
    
    # í´ë˜ìŠ¤ë³„ ì •í™•ë„
    conf_matrix = confusion_matrix(labels, preds)
    class_acc = conf_matrix.diagonal() / conf_matrix.sum(axis=1)
    
    return {
        "accuracy": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1,
        "class_0_acc": class_acc[0] if len(class_acc) > 0 else 0,
        "class_1_acc": class_acc[1] if len(class_acc) > 1 else 0,
        "class_2_acc": class_acc[2] if len(class_acc) > 2 else 0,
    }

# ============================================
# 5. í•™ìŠµ ì„¤ì •
# ============================================

print("\nâš™ï¸ í•™ìŠµ ì„¤ì • ì¤‘...")

training_args = TrainingArguments(
    # ì¶œë ¥ ë””ë ‰í† ë¦¬
    output_dir=CONFIG["output_dir"],
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„°
    num_train_epochs=CONFIG["num_train_epochs"],
    per_device_train_batch_size=CONFIG["batch_size"],
    per_device_eval_batch_size=CONFIG["batch_size"],
    learning_rate=CONFIG["learning_rate"],
    weight_decay=CONFIG["weight_decay"],
    
    # í‰ê°€ ë° ì €ì¥
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    
    # ë¡œê¹…
    logging_dir=f"{CONFIG['output_dir']}/logs",
    logging_strategy="steps",
    logging_steps=5,
    
    # ê¸°íƒ€
    seed=CONFIG["seed"],
    push_to_hub=False,
    report_to="none",  # wandb ë“± ë¹„í™œì„±í™”
    no_cuda=True,  # CPU ì‚¬ìš© ê°•ì œ (accelerate í˜¸í™˜ì„±)
)

# Trainer ìƒì„±
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
)

print("âœ… í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ!")

# ============================================
# 6. Fine-tuning ì‹¤í–‰!
# ============================================

print("\n" + "="*60)
print("ğŸ”¥ Fine-tuning ì‹œì‘!")
print("="*60)

try:
    train_result = trainer.train()
    
    print("\nâœ… Fine-tuning ì™„ë£Œ!")
    print(f"ğŸ“Š ìµœì¢… Loss: {train_result.training_loss:.4f}")
    
except Exception as e:
    print(f"\nâŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    raise

# ============================================
# 7. í‰ê°€
# ============================================

print("\nğŸ“Š ê²€ì¦ ë°ì´í„° í‰ê°€ ì¤‘...")

eval_results = trainer.evaluate()

print("\n" + "="*60)
print("ğŸ“ˆ ìµœì¢… í‰ê°€ ê²°ê³¼")
print("="*60)
print(f"ì •í™•ë„ (Accuracy): {eval_results['eval_accuracy']:.2%}")
print(f"ì •ë°€ë„ (Precision): {eval_results['eval_precision']:.2%}")
print(f"ì¬í˜„ìœ¨ (Recall): {eval_results['eval_recall']:.2%}")
print(f"F1 Score: {eval_results['eval_f1']:.2%}")
print(f"\ní´ë˜ìŠ¤ë³„ ì •í™•ë„:")
print(f"  - ë¶€ì • (0): {eval_results['eval_class_0_acc']:.2%}")
print(f"  - ì¤‘ë¦½ (1): {eval_results['eval_class_1_acc']:.2%}")
print(f"  - ê¸ì • (2): {eval_results['eval_class_2_acc']:.2%}")
print("="*60)

# ============================================
# 8. ëª¨ë¸ ì €ì¥
# ============================================

print("\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")

final_model_dir = "./koelectra-game-sentiment"
model.save_pretrained(final_model_dir)
tokenizer.save_pretrained(final_model_dir)

print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {final_model_dir}")

# ============================================
# 9. í…ŒìŠ¤íŠ¸
# ============================================

print("\nğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸...")

test_texts = [
    "ë¡œê·¸ì¸ì´ ì•ˆ ë¼ìš” ê³„ì† ì˜¤ë¥˜ë‚˜ìš”",
    "ì´ë²¤íŠ¸ ê¸°ê°„ì´ ì–¸ì œê¹Œì§€ì¸ê°€ìš”?",
    "ì—…ë°ì´íŠ¸ í›„ ì •ë§ ì¢‹ì•„ì¡Œì–´ìš” ê°ì‚¬í•©ë‹ˆë‹¤"
]

label_names = ["ë¶€ì •", "ì¤‘ë¦½", "ê¸ì •"]

for text in test_texts:
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    
    with torch.no_grad():
        outputs = model(**inputs)
        pred = torch.argmax(outputs.logits, dim=1).item()
    
    print(f"  '{text}'")
    print(f"  â†’ ì˜ˆì¸¡: {label_names[pred]}\n")

# ============================================
# ì™„ë£Œ!
# ============================================

print("="*60)
print("ğŸ‰ Fine-tuning ì™„ë£Œ!")
print("="*60)
print(f"ğŸ“ ëª¨ë¸ ìœ„ì¹˜: {final_model_dir}")
print(f"ğŸ“Š ì •í™•ë„: {eval_results['eval_accuracy']:.2%}")
print("\në‹¤ìŒ ë‹¨ê³„:")
print("1. src/koelectra_classifier.py ìˆ˜ì •")
print("2. Fine-tuned ëª¨ë¸ ê²½ë¡œ ë³€ê²½")
print("3. dashboard.py ì¬ì‹¤í–‰")
print("="*60)

